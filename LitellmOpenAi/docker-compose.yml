services:

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: always
    command: >
      bash -c "bash start.sh"
    ports:
      - "3000:8080"
    volumes:
      - open-webui:/app/backend/data
    networks:
      - networkService
    env_file: ../.env
    depends_on:
      - LitellmOpenAi

  LitellmOpenAi:
    build: .
    image: azure:abait-ta
    container_name: LitellmOpenAi
    volumes:
    - .:/LitellmOpenAi
    networks:
      - networkService
    ports:
      - "4000:4000"
    env_file: ../.env
    
#  Add preumethose for monitoring
  prometheus:
    image: prom/prometheus:v2.37.0
    container_name: prometheus
    volumes:
      - ./prometheuse.yaml:/etc/prometheus/prometheus.yml
    networks:
      - networkService
    ports:
      - "9090:9090"
    depends_on:
      - LitellmOpenAi

# Here we can Use promQL
  grafana:
    image: grafana/grafana:9.0.0
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "5000:3000"
    networks:
      - networkService
    depends_on:
      - prometheus

  nginx:
    build:
      context: ./nginx_setup
      dockerfile: dockerfile.nginx
    image: nginx:canis
    container_name: nginx
    ports:
      - "443:443"
    # volumes:
      # - ./nginx_setup/conf.d:/etc/nginx/conf.d
      # - ./ssl:/etc/nginx/ssl
    networks:
      - networkService
    depends_on:
      open-webui:
        condition: service_healthy


volumes:
  open-webui:
  ollama:

networks:
  networkService:
    driver: bridge
    name: Inception-net