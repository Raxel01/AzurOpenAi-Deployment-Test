services:

  open-webui:
    build:
      context: ./openweb-ui
      dockerfile : dockerfile.openwebui
    image: open-webui:llm
    container_name: open-webui
    restart: always
    #  && python3 populate_db.py
    command: >
      bash -c "bash start.sh"
    ports:
      - "3000:8080"
    volumes:
      - open-webui:/app/backend/data
      - ./openweb-ui/populate_db.py:/app/backend/populate_db.py
    networks:
      - networkService
    env_file: ../.env
    depends_on:
      - LitellmOpenAi

  LitellmOpenAi:
    build:
      context: ./Litellm_setup
      dockerfile: dockerfile.litellm
    image: azure:llm
    container_name: LitellmOpenAi
    volumes:
    - ./Litellm_setup:/LitellmOpenAi
    networks:
      - networkService
    ports:
      - "4000:4000"
    env_file: ../.env
    
#  Add preumethose for monitoring
  prometheus:
    image: prom/prometheus:v2.37.0
    container_name: prometheus
    volumes:
      - ./prometheus_setup/prometheuse.yaml:/etc/prometheus/prometheus.yml
    networks:
      - networkService
    ports:
      - "9090:9090"
    depends_on:
      - LitellmOpenAi

# Here we can Use promQL
  grafana:
    build: 
      context: ./grafana
      dockerfile: dockerfile.grafana
    image: grafana:llm
    container_name: grafana
    ports:
      - "5000:3000"
    networks:
      - networkService
    depends_on:
      - prometheus
    restart: unless-stopped
    volumes:
      - grafana-storage:/var/lib/grafana

  nginx:
    build:
      context: ./nginx_setup
      dockerfile: dockerfile.nginx
    image: nginx:llm
    container_name: nginx
    ports:
      - "443:443"
    networks:
      - networkService
    depends_on:
      open-webui:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "service", "nginx", "status"]
      interval: 20s
      timeout: 10s
      retries: 6
      start_period: 5s

  nginx-exporter:
    build:
      context: ./exporters
      dockerfile: dockerfile.nginx_exporter
    container_name: nginx-exporter
    depends_on:
      nginx:
        condition: service_healthy
    env_file:
      - ../.env
    command:
      - --nginx.scrape-uri=${NGINX_SCRAPE_URI}
    networks:
      - networkService
    restart: always

  node-exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node-exporter
    depends_on:
      nginx:
        condition: service_healthy
    networks:
      - networkService
    restart: always



volumes:
  open-webui:
  ollama:
  grafana-storage:

networks:
  networkService:
    driver: bridge
    name: Inception-net