services:

  open-webui:
    build:
      context: ./openweb-ui
      dockerfile : dockerfile.openwebui
    image: open-webui:llm
    container_name: open-webui
    restart: always
    command: >
      bash -c "bash start.sh && python3 populate_db.py"
    ports:
      - "3000:8080"
    volumes:
      - open-webui:/app/backend/data
      - ./openweb-ui/populate_db.py:/app/backend/populate_db.py
    networks:
      - networkService
    env_file: ../.env
    depends_on:
      - LitellmOpenAi

  LitellmOpenAi:
    build:
      context: ./Litellm_setup
      dockerfile: dockerfile.litellm
    image: azure:llm
    container_name: LitellmOpenAi
    volumes:
    - ./Litellm_setup:/LitellmOpenAi
    networks:
      - networkService
    ports:
      - "4000:4000"
    env_file: ../.env
    
#  Add preumethose for monitoring
  prometheus:
    image: prom/prometheus:v2.37.0
    container_name: prometheus
    volumes:
      - ./prometheus_setup/prometheuse.yaml:/etc/prometheus/prometheus.yml
    networks:
      - networkService
    ports:
      - "9090:9090"
    depends_on:
      - LitellmOpenAi

# Here we can Use promQL
  grafana:
    image: grafana/grafana:9.0.0
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "5000:3000"
    networks:
      - networkService
    depends_on:
      - prometheus

  nginx:
    build:
      context: ./nginx_setup
      dockerfile: dockerfile.nginx
    image: nginx:llm
    container_name: nginx
    ports:
      - "443:443"
    networks:
      - networkService
    depends_on:
      open-webui:
        condition: service_healthy


volumes:
  open-webui:
  ollama:

networks:
  networkService:
    driver: bridge
    name: Inception-net