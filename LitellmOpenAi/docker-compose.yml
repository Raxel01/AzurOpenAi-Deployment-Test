services:
  # ollama:
  #   image: ollama/ollama
  #   container_name: ollama
  #   command: >
  #     "serve"
  #   volumes:
  #   - ollama:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   networks:
  #     - networkService
  
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: always
    command: >
      bash -c "bash start.sh"
    ports:
      - "3000:8080"
    volumes:
      - open-webui:/app/backend/data
    networks:
      - networkService
    env_file: ../.env
    depends_on:
      - LitellmOpenAi

  LitellmOpenAi:
    build: .
    image: azure:abait-ta
    container_name: LitellmOpenAi
    volumes:
    - .:/LitellmOpenAi
    networks:
      - networkService
    ports:
      - "4000:4000"
    env_file: ../.env
    
#  Add preumethose for monitoring
  prometheus:
    image: prom/prometheus:v2.37.0
    container_name: prometheus
    volumes:
      - ./prometheuse.yaml:/etc/prometheus/prometheus.yml
    networks:
      - networkService
    ports:
      - "9090:9090"

# Here we can Use promQL
  grafana:
    image: grafana/grafana:9.0.0
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "5000:3000"
    networks:
      - networkService

volumes:
  open-webui:
  ollama:

networks:
  networkService:
    driver: bridge
    name: Inception-net